{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JyXGCxDy0Fs"
      },
      "outputs": [],
      "source": [
        "# Librerias para crear los vectores de caracteristicas\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pywt\n",
        "import pickle\n",
        "# Liberias para crear el modelo de clasificacion\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, f1_score, precision_score,confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(input_path, output_path, target_size=(256, 256)):\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    images = os.listdir(input_path)\n",
        "\n",
        "    for image_name in images:\n",
        "        image_path = os.path.join(input_path, image_name)\n",
        "        imagen = Image.open(image_path)\n",
        "\n",
        "        imagen = imagen.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "        output_image_path = os.path.join(output_path, image_name)\n",
        "        imagen.save(output_image_path)\n",
        "\n",
        "def load_labels(input_path):\n",
        "    images = os.listdir(input_path)\n",
        "    labels = [image_name[:3] for image_name in images]\n",
        "    return labels\n",
        "\n",
        "def extract_features(image, num_levels=1):\n",
        "    LL = image.copy()\n",
        "    for _ in range(num_levels):\n",
        "        LL, (LH, HL, HH) = pywt.dwt2(LL, 'haar')\n",
        "        LL = np.max(LL, axis=0)\n",
        "        LH = np.max(LH, axis=0)\n",
        "        HL = np.max(HL, axis=0)\n",
        "        HH = np.max(HH, axis=0)\n",
        "        LL = np.concatenate((LL, LH, HL, HH))\n",
        "\n",
        "    return LL.flatten()\n",
        "\n",
        "def preprocess_and_extract_features(input_path, output_path, num_levels=1):\n",
        "    preprocess_images(input_path, output_path)\n",
        "    images = os.listdir(output_path)\n",
        "    features_list = []\n",
        "\n",
        "    for image_name in images:\n",
        "        image_path = os.path.join(output_path, image_name)\n",
        "        imagen = Image.open(image_path)\n",
        "        imagen = imagen.convert('L')\n",
        "        imagen = np.array(imagen)\n",
        "        features = extract_features(imagen, num_levels)\n",
        "        features_list.append(features)\n",
        "\n",
        "    return features_list\n",
        "\n",
        "def normalize_features(features):\n",
        "    scaler = MinMaxScaler()\n",
        "    features_normalized = [scaler.fit_transform(feature.reshape(-1, 1)).flatten() for feature in features]\n",
        "    return features_normalized\n"
      ],
      "metadata": {
        "id": "HDakBIFCzY3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base de datos\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "# Cargando datos\n",
        "#Nombre_Data_Set = 'iris - iris.csv'\n",
        "#iris = pd.read_csv(Nombre_Data_Set)\n",
        "\n",
        "# Directorios de entrada y salida\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_images = '/content/drive/MyDrive/ML-1/images/'\n",
        "path_save = '/content/drive/MyDrive/ML-1/images_p/'\n",
        "\n",
        "# Obtener etiquetas\n",
        "labels = load_labels(path_images)\n",
        "\n",
        "# Obtener características independientes\n",
        "indep = preprocess_and_extract_features(path_images, path_save, num_levels=1)\n",
        "\n",
        "\n",
        "# Normalizar las características independientes\n",
        "indep_normalized = normalize_features(indep)\n",
        "\n",
        "# Combinar etiquetas y características independientes en un diccionario\n",
        "dataset = {'labels': labels, 'indep': indep_normalized}\n",
        "\n",
        "# Nombre del archivo para guardar el dataset\n",
        "output_file = 'dataset.pkl'\n",
        "\n",
        "# Guardar el dataset en un archivo utilizando pickle\n",
        "with open(output_file, 'wb') as file:\n",
        "    pickle.dump(dataset, file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm1xBRAxzcoA",
        "outputId": "fbcd2bcd-0dff-4683-fc9a-a2db31038ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dataset.pkl', 'rb') as file:\n",
        "    dataset = pickle.load(file)\n",
        "index = np.arange(len(dataset['labels']))\n",
        "rnd = np.random.RandomState(123)\n",
        "suffle_index = rnd.permutation(index)\n",
        "\n",
        "x_shuffle, y_shuffle = [], []\n",
        "for i in range(len(suffle_index)):\n",
        "    x_shuffle.append(dataset['indep'][suffle_index[i]])\n",
        "    y_shuffle.append(dataset['labels'][suffle_index[i]])\n",
        "x_shuffle = np.array(x_shuffle)\n",
        "y_shuffle = np.array(y_shuffle)\n",
        "\n"
      ],
      "metadata": {
        "id": "62zwgD0uz8mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear', decision_function_shape='ovr')\n",
        "\n",
        "for i in range(3,11):\n",
        "  kf = StratifiedKFold(n_splits=i, shuffle=True, random_state=42)\n",
        "\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1 = []\n",
        "  c_matrix = []\n",
        "\n",
        "  for t, v in kf.split(x_shuffle, y_shuffle):\n",
        "      x_trainf = x_shuffle[t]\n",
        "      y_trainf = y_shuffle[t]\n",
        "      x_valf = x_shuffle[v]\n",
        "      y_valf = y_shuffle[v]\n",
        "\n",
        "      svm_model.fit(x_trainf, y_trainf)\n",
        "\n",
        "      y_pred = svm_model.predict(x_valf)\n",
        "\n",
        "      p = precision_score(y_valf, y_pred, average='weighted')\n",
        "      r = recall_score(y_valf, y_pred, average='weighted')\n",
        "      f = f1_score(y_valf, y_pred, average='weighted')\n",
        "      confusion = confusion_matrix(y_valf, y_pred)\n",
        "\n",
        "      precision.append(p)\n",
        "      recall.append(r)\n",
        "      f1.append(f)\n",
        "      c_matrix.append(confusion)\n",
        "\n",
        "\n",
        "  print(\"k: \"+str(i))\n",
        "  results = pd.DataFrame({\n",
        "      'Precision': precision,\n",
        "      'Recall': recall,\n",
        "      'F1-Score': f1\n",
        "  })\n",
        "\n",
        "  print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryRRi1jk0djn",
        "outputId": "b8a32642-9bec-4a91-8fbb-c378d31c1f6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k: 3\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.436776  0.431655  0.423478\n",
            "1   0.445147  0.451264  0.443075\n",
            "2   0.464749  0.469314  0.461984\n",
            "k: 4\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.456517  0.447115  0.434810\n",
            "1   0.446792  0.447115  0.437022\n",
            "2   0.460683  0.447115  0.447195\n",
            "3   0.446527  0.456731  0.446270\n",
            "k: 5\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.479495  0.461078  0.455851\n",
            "1   0.429351  0.431138  0.417441\n",
            "2   0.491232  0.475904  0.471771\n",
            "3   0.472415  0.445783  0.443873\n",
            "4   0.466658  0.475904  0.466529\n",
            "k: 6\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.471552  0.453237  0.449194\n",
            "1   0.473435  0.467626  0.459366\n",
            "2   0.497886  0.489209  0.481690\n",
            "3   0.452782  0.446043  0.442474\n",
            "4   0.493280  0.478261  0.472325\n",
            "5   0.485285  0.485507  0.480457\n",
            "k: 7\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.443372  0.428571  0.423779\n",
            "1   0.520572  0.495798  0.495719\n",
            "2   0.498923  0.504202  0.489577\n",
            "3   0.486160  0.478992  0.467353\n",
            "4   0.469755  0.470588  0.463919\n",
            "5   0.425278  0.420168  0.408664\n",
            "6   0.485102  0.483051  0.478817\n",
            "k: 8\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.400025  0.413462  0.395892\n",
            "1   0.506942  0.461538  0.469410\n",
            "2   0.480148  0.461538  0.457598\n",
            "3   0.491016  0.490385  0.478136\n",
            "4   0.494615  0.461538  0.467937\n",
            "5   0.502028  0.471154  0.470615\n",
            "6   0.460521  0.471154  0.453549\n",
            "7   0.466716  0.471154  0.458452\n",
            "k: 9\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.432186  0.440860  0.424901\n",
            "1   0.463745  0.440860  0.432779\n",
            "2   0.443932  0.462366  0.443255\n",
            "3   0.534153  0.505376  0.496989\n",
            "4   0.496086  0.478261  0.472273\n",
            "5   0.456409  0.456522  0.443974\n",
            "6   0.495039  0.489130  0.479477\n",
            "7   0.495851  0.510870  0.491197\n",
            "8   0.465498  0.467391  0.456063\n",
            "k: 10\n",
            "   Precision    Recall  F1-Score\n",
            "0   0.440636  0.428571  0.411327\n",
            "1   0.507703  0.476190  0.473673\n",
            "2   0.511388  0.493976  0.483624\n",
            "3   0.493987  0.506024  0.484354\n",
            "4   0.484557  0.493976  0.477917\n",
            "5   0.520917  0.506024  0.501896\n",
            "6   0.425344  0.433735  0.413456\n",
            "7   0.472514  0.457831  0.454362\n",
            "8   0.559707  0.566265  0.549654\n",
            "9   0.430386  0.433735  0.424230\n"
          ]
        }
      ]
    }
  ]
}
